{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### HSML 6295 Preparing Your Data Set\n",
                "\n",
                "#### I. Properties of a .csv file suitable for analysis    \n",
                "\n",
                "The .csv should be laid out as follows:\n",
                "\n",
                "1. \n",
                "Each row (except the first) should represent an observation, e.g. a patient, a hospital, a jurisdiction or country.\n",
                "\n",
                "2. \n",
                "The first line (row) contains the variable names\n",
                "\n",
                "3. \n",
                "The second through last rows contain the values of the variables.\n",
                "\n",
                "4.\n",
                "Each column (except possibly the first) should represent a variable -- either the response or a predictor.\n",
                "\n",
                "5.\n",
                "If they are available, the first column contains the observation identifiers, which serve as data point labels in graphs, e.g. the names or ID numbers. This column should be called \"label\".\n",
                "\n",
                "6.\n",
                "The second column should be the variable representing the response.\n",
                "\n",
                "7.\n",
                "The third through last columns should be the variables representing the possible predictors.\n",
                "\n",
                "8.\n",
                "The data set should contain no missing values, which may show as blank spaces, a dot \".\", \"NA\". \n",
                "See sections III and IV for code to remove variables and observations with missing values.\n",
                "\n",
                "9.\n",
                "All the variables should be numeric, i.e. they should have numbers as values, not strings (text).\n",
                "See section V for code to convert categorical string variables into set of binary indicator (\"dummy\") variables.\n",
                "\n",
                "10. \n",
                "The ideal data set should have at least 20 observations (rows) and at least 10 variables (columns). The techniques that we are studying tend to behave in a weird way when the data set is smaller than that.\n",
                "\n",
                "11.\n",
                "The number of variables should not exceed the number of observations. Again, the techniques that we are studying work better when the number of observations, denoted $n$, is substantially larger than the number of variables, denoted $p$:  $n > p$. The chapter \"6.4 Considerations in High Dimensions\" in the textbook covers how we need to adapt the methods when $p > n$.\n",
                "\n",
                "12.\n",
                "The variables should capture different dimensions of the problem. The techniques still work but the results won't be too informative (e.g. which variable is the strongest predictor); the predictive performance may also be stronger if you add variables that capture additional dimensions. For instance, if suppose your predictors consist of 5 variables, each measuring the proportion of the population in a 20-year age bracket, and 4 more variables, each measuring the proportion of a religious group in the population. In this case, your predictors only represent two dimensions, namely the age structure and the religious makeup of the population.\n",
                "\n",
                "#### II. Load a .csv File\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# read in the data set:\n",
                "mydata = read.csv(\"HSML 6295 ds High School Scores.csv\")\n",
                "# describe the data set:\n",
                "str(mydata)                               \n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### III. Drop variables (columns) with too many missing values\n",
                "\n",
                "Show number and proportion of missing values for each variable:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# define the function that computes the proportion of missing values\n",
                "propmiss <- function(dataframe) {\n",
                "\tm <- sapply(dataframe, function(x) {\n",
                "\t\tdata.frame(\n",
                "\t\t\tnmiss=sum(is.na(x)), \n",
                "\t\t\tn=length(x), \n",
                "\t\t\tpropmiss=sum(is.na(x))/length(x)\n",
                "\t\t)\n",
                "\t})\n",
                "\td <- data.frame(t(m))\n",
                "\td <- sapply(d, unlist)\n",
                "\td <- as.data.frame(d)\n",
                "\td$variable <- row.names(d)\n",
                "\trow.names(d) <- NULL\n",
                "\td <- cbind(d[ncol(d)],d[-ncol(d)])\n",
                "\treturn(d[order(-d$propmiss), ])\n",
                "}\n",
                "# run the function that computes the proportion of missing values\n",
                "propmiss(mydata)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "Drop select variables, e.g. with at least 10% missing values\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dim(mydata)\n",
                "# create list of variables to drop:\n",
                "vars_to_drop = names(mydata) %in% c(\"socst\", \"science\") \n",
                "mydata <- mydata[!vars_to_drop]\n",
                "dim(mydata)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### IV. Drop observations with at least one missing value\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "mydata = na.omit(mydata)\n",
                "dim(mydata)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### V. Convert categorical string variables\n",
                "\n",
                "Convert categorical string variables to sets of binary indicator (\"dummy\") variables:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# install.packages(\"dummies\")\n",
                "# load the library \"dummies\":\n",
                "library(dummies)\n",
                "# create new data frame in which the factor variables \n",
                "#    have been replaced by sets of \"dummies\":\n",
                "mydata <- dummy.data.frame(mydata, sep = \".\")\n",
                "# display the result:\n",
                "str(mydata)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### VI. Display summary statistics for new data frame\n",
                "\n",
                "The means of the dummy variables show the distributions of the categories.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "library(stargazer)\n",
                "stargazer(mydata, \n",
                "          summary.stat = c(\"n\", \"mean\", \"median\", \"sd\"),\n",
                "          type = \"text\", title=\"Descriptive statistics\", digits=2)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### VII. Save the new data frame as a .csv file\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "write.csv(mydata, file = \"HSML 6295 ds High School Scores CLEAN.csv\")\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### VIII. Sample code for the results table\n",
                "\n",
                "\n",
                "|                   | **Model 1**   | **Model 2**   | **Model 3**\n",
                "| ---               | ---           | ---           | ---\n",
                "| **Training Set**  | PP1_train     | PP2_train     | PP3_train\n",
                "| **Test Set**      |\tPP1_test      | PP2_test      | PP3_test\n"
            ]
        }
    ],
    "metadata": {
        "anaconda-cloud": "",
        "kernelspec": {
            "display_name": "R",
            "langauge": "R",
            "name": "ir"
        },
        "language_info": {
            "codemirror_mode": "r",
            "file_extension": ".r",
            "mimetype": "text/x-r-source",
            "name": "R",
            "pygments_lexer": "r",
            "version": "3.4.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}
