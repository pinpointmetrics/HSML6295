{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### HSML 6295 Session 4 (Cross-Validation and Model Selection) - ANSWERS\n",
                "\n",
                "#### I. Cross-Validation\n",
                "\n",
                "We use a data set that I created using the ad-hoc query system wonder.cdc.gov, which accesses large online databases and is maintained by the Centers for Disease Control and Prevention.\n",
                "\n",
                "This data set includes crude death rates per 100,000 for ages 0-84 for years 2010-2016.\n",
                "\n",
                "Read in the data set\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "rates = read.csv(\"HSML 6295 s4 US Death Rates by Age.csv\") \n",
                "str(rates)\n",
                "plot(Death_Rate ~ Age, data = rates, \n",
                "     xlab = \"Age (Years)\", ylab = \"Deaths per 100,000\")\n",
                "plot(Death_Rate ~ Age, data = rates, \n",
                "     xlab = \"Age (Years)\", ylab = \"Deaths per 100,000\", xlim = c(0,30), ylim = c(0,1000))\n",
                "plot(log(Death_Rate) ~ Age, data = rates, \n",
                "     xlab = \"Age (Years)\", ylab = \"log(Deaths per 100,000)\")\n",
                "plot(log(Death_Rate) ~ Age, data = rates, \n",
                "     xlab = \"Age (Years)\", ylab = \"log(Deaths per 100,000)\", \n",
                "     xlim = c(0,30), ylim = c(2,7))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "library(boot)\n",
                "\n",
                "# Set the value of the randomization seed\n",
                "  set.seed(1)\n",
                "\n",
                "# Define subset of data frame\n",
                "  subset = subset(rates, Age >= 0 & Year >= 2016)                   \n",
                "\n",
                "# Set number of folds\n",
                "  k=5\n",
                "\n",
                "# Matrix of MSE results\n",
                "  (cv.error = rbind(rep(0,10), rep(0,10), rep(0,10)))\n",
                "\n",
                "# Loop over polynomial degrees\n",
                "for (i in 1:10){\n",
                "# Fit polynomial on subset\n",
                "  glm.fit = glm(Death_Rate ~ poly(Age, i), data = subset)         \n",
                "# Predict response on full data set\n",
                "  pred = predict(glm.fit, subset)                                 \n",
                "# Training MSE\n",
                "  cv.error[1,i] = round(mean((subset$Death_Rate - pred)^2),0)     \n",
                "# LOOCV Test MSE\n",
                "  cv.error[2,i] = round(cv.glm(subset, glm.fit)$delta[1],0)       \n",
                "# K-Fold CV Test MSE\n",
                "  cv.error[3,i] = round(cv.glm(subset, glm.fit, K=k)$delta[1],0)  \n",
                "}\n",
                "\n",
                "# Extract the values of the polynomial degree that minimize the MSEs\n",
                "arg_min_train = cv.error[1,][which.min(cv.error[1,])]\n",
                "arg_min_loocv = cv.error[2,][which.min(cv.error[2,])]\n",
                "arg_min_cv    = cv.error[3,][which.min(cv.error[3,])]\n",
                "\n",
                "# Plot the MSE values for polynomial degrees 1 through 10\n",
                "plot(log(cv.error[1,]), type=\"l\", xlab=\"Degree of Polynomial\", ylab=\"log(MSE)\",\n",
                "     col=\"red\", lwd=1, pch=15, cex = 0.8, bty=\"l\")\n",
                "lines(log(cv.error[2,]), type=\"l\", col=\"blue\", lwd=1, pch=16, cex = 0.8)\n",
                "lines(log(cv.error[3,]), type=\"l\", col=\"purple\", lwd=1, pch=17, cex = 0.8)\n",
                "points(which.min(cv.error[1,]),log(arg_min_train),col=\"red\",cex=1,pch=15)\n",
                "points(which.min(cv.error[2,]),log(arg_min_loocv),col=\"blue\",cex=1,pch=16)\n",
                "points(which.min(cv.error[3,]),log(arg_min_cv),col=\"purple\",cex=1,pch=17)\n",
                "legend(\"top\", legend =  c(paste(\"Training MSE:\", arg_min_train), \n",
                "                          paste(\"LOOCV Test MSE:\", arg_min_loocv), \n",
                "                          paste(k,\"- Fold CV Test MSE:\",arg_min_cv)), \n",
                "       col = c(\"red\",\"blue\",\"purple\"), pch = c(15,16,17), bty = \"n\", \n",
                "       text.col = c(\"red\",\"blue\",\"purple\"), horiz = F)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Knowledge Check 1**\n",
                "\n",
                "Compute the training MSE, the LOOCV test MSE, and the 5-fold CV test MSE for the age ranges shown in the table below and find the value of the complexity parameter (the degree of the polynomial) that minimizes each error measure. Do the shapes of the graphs representing the 3 measures change when you change the value of the randomization seed?\n",
                "\n",
                "Hint: Modify the following line in the code chunk above\n",
                "\n",
                "`subset = subset(rates, Age >= 0 & Year >= 2016)`\n",
                "\n",
                "\n",
                "| Age Range (Years)                        | 0-84 | 1-84 | 2-84 | 20-84 | 40-84 | 65-84 |\n",
                "| ---                                      | ---: | ---: | ---: | ---:  | ---:  | ---:  |\n",
                "| Degree That Minimizes Training MSE       |   10 |      |      |       |       |       |\n",
                "| Degree That Minimizes LOOCV Test MSE     |    6 |      |      |       |       |       |\n",
                "| Degree That Minimizes 5-Fold CV Test MSE |    6 |      |      |       |       |       |\n",
                "\n",
                "\n",
                "**Answer:**\n",
                "\n",
                "| Age Range (Years)                        | 0-84 | 1-84 | 2-84 | 20-84 | 40-84 | 65-84 |\n",
                "| ---                                      | ---: | ---: | ---: | ---:  | ---:  | ---:  |\n",
                "| Degree That Minimizes Training MSE       |   10 |   10 |   10 |     9 |    10 |    10 |\n",
                "| Degree That Minimizes LOOCV Test MSE     |    6 |   10 |    8 |     9 |     5 |     4 |\n",
                "| Degree That Minimizes 5-Fold CV Test MSE |    6 |   10 |    8 |     9 |     5 |     4 |\n",
                "\n",
                "\n",
                "**Knowledge Check 2**\n",
                "\n",
                "Compute the training MSE, the LOOCV test MSE, and the 5-fold CV test MSE for the age range 0-84 but now change the value of the randomization seed as shown in the table below and find the value of the complexity parameter (the degree of the polynomial) that minimizes each error measure. Do the shapes of the graphs representing the 3 measures change when you change the value of the randomization seed?\n",
                "\n",
                "Hint: Modify the following line in the code chunk above\n",
                "\n",
                "`set.seed(1)`\n",
                "\n",
                "\n",
                "\n",
                "| Seed Value                               |    1 |    2 |    3 |    4 |    6 | \n",
                "| ---                                      | ---: | ---: | ---: | ---: | ---: | \n",
                "| Degree That Minimizes Training MSE       |   10 |      |      |      |      |\n",
                "| Degree That Minimizes LOOCV Test MSE     |    6 |      |      |      |      |\n",
                "| Degree That Minimizes 5-Fold CV Test MSE |    6 |      |      |      |      |\n",
                "\n",
                "**Answer:**\n",
                "\n",
                "| Seed Value                               |    1 |    2 |    3 |    4 |    6 | \n",
                "| ---                                      | ---: | ---: | ---: | ---: | ---: | \n",
                "| Degree That Minimizes Training MSE       |   10 |   10 |   10 |   10 |   10 |\n",
                "| Degree That Minimizes LOOCV Test MSE     |    6 |    6 |    6 |    6 |    6 |\n",
                "| Degree That Minimizes 5-Fold CV Test MSE |    6 |   10 |    6 |    6 |   10 |\n",
                "\n",
                "**Knowledge Check 3**\n",
                "\n",
                "Compute the K-fold CV test MSE for the age range 0-84 and seed value 1 but now change the number of folds as shown in the table below and find the value of the complexity parameter (the degree of the polynomial) that minimizes the error measure.\n",
                "\n",
                "Hint: Modify the following line in the code chunk above\n",
                "\n",
                "`k=5`\n",
                "\n",
                "\n",
                "\n",
                "| Number of Folds (K)                      |    2 |    3 |    4 |    5 |    6 |    7 |  \n",
                "| ---                                      | ---: | ---: | ---: | ---: | ---: | ---: | \n",
                "| Degree That Minimizes K-Fold CV Test MSE |      |      |      |    6 |      |      |\n",
                "\n",
                "**Answer:**\n",
                "\n",
                "| Number of Folds (K)                      |    2 |    3 |    4 |    5 |    6 |    7 |  \n",
                "| ---                                      | ---: | ---: | ---: | ---: | ---: | ---: | \n",
                "| Degree That Minimizes K-Fold CV Test MSE |    7 |    6 |   10 |    6 |    6 |    7 |\n",
                "\n",
                "\n",
                "**Knowledge Check 4**\n",
                "\n",
                "Compute the training MSE, the LOOCV test MSE, and the 5-fold CV test MSE for the age range 65-84 and seed value 1 but now change the range of years as shown in the table below and find the value of the complexity parameter (the degree of the polynomial) that minimizes each error measure. Also pay attention to the shape of the graphs representing the 3 measures and in particular to the distance between the value of the training MSE and the two test MSEs when the degree is 10.\n",
                "\n",
                "Hint: Modify the following line in the code chunk above\n",
                "\n",
                "`subset = subset(rates, Age >= 0 & Year >= 2016)`\n",
                "\n",
                "\n",
                "| Years Included                           | 2016 | 2015-2016 | 2013-2016 | 2010-2016 |\n",
                "| ---                                      | ---: |      ---: |      ---: |     ---:  |\n",
                "| Degree That Minimizes Training MSE       |   10 |           |           |           |\n",
                "| Degree That Minimizes LOOCV Test MSE     |    4 |           |           |           |\n",
                "| Degree That Minimizes 5-Fold CV Test MSE |    4 |           |           |           |\n",
                "\n",
                "**Answer:**\n",
                "\n",
                "| Years Included                           | 2016 | 2015-2016 | 2013-2016 | 2010-2016 |\n",
                "| ---                                      | ---: |      ---: |      ---: |      ---: |\n",
                "| Degree That Minimizes Training MSE       |   10 |        10 |        10 |        10 |\n",
                "| Degree That Minimizes LOOCV Test MSE     |    4 |         4 |         4 |         4 |\n",
                "| Degree That Minimizes 5-Fold CV Test MSE |    4 |         3 |         8 |         3 |\n",
                "\n",
                "#### II. Summary Statistics for the \"Physician Office Visits\" Data Set\n",
                "\n",
                "Load data set\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "visits = read.csv(\"HSML 6295 s4 Visits.csv\")\n",
                "str(visits)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "Show summary statistics for continuous variables\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "library(stargazer)\n",
                "stargazer(visits, \n",
                "          type = \"text\", \n",
                "          summary.stat = c(\"n\", \"mean\", \"sd\", \"min\", \"p25\", \"median\", \"p75\", \"max\"),\n",
                "          title=\"Descriptive statistics\", digits=1)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### III. Compute the Least Squares Fit (No Subset Selection or Shrinkage)\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "summary(lm(Visits ~ ., visits))\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Knowledge Check 5**\n",
                "\n",
                "Load the \"HSML 6295 s4 Contacts.csv\" data set and compute summary statistics and the least squares estimates.\n",
                "\n",
                "**Answer:**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "contacts = read.csv(\"HSML 6295 s4 Contacts.csv\")\n",
                "str(contacts)\n",
                "library(stargazer)\n",
                "stargazer(contacts, \n",
                "          type = \"text\", \n",
                "          summary.stat = c(\"n\", \"mean\", \"sd\", \"min\", \"p25\", \"median\", \"p75\", \"max\"),\n",
                "          title=\"Descriptive statistics\", digits=1)\n",
                "summary(lm(Visits ~ ., contacts))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### IV. Subset Selection\n",
                "\n",
                "Compute RSS and adjusted training errors for all possible *j*-variable models\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "library(leaps)\n",
                "predictors = ncol(visits)-1\n",
                "regfit.full = regsubsets(Visits ~ ., data = visits, nvmax=predictors)\n",
                "(reg.summary = summary(regfit.full))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**IV.A. Indirectly Estimate the Test Error (Adjust the Training Error) **\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# R-Squared\n",
                "plot(reg.summary$rsq ,xlab=\"Number of Predictors\",ylab=\"R-Squared\",type=\"l\")\n",
                "points(which.max(reg.summary$rsq),reg.summary$rsq[which.max(reg.summary$rsq)], \n",
                "       col=\"red\",cex=2,pch=20)\n",
                "plot(regfit.full,scale=\"r2\")\n",
                "\n",
                "# Adjusted R-Squared\n",
                "plot(reg.summary$adjr2 ,xlab=\"Number of Predictors\",ylab=\"Adjusted R-Squared\",type=\"l\")\n",
                "points(which.max(reg.summary$adjr2),reg.summary$adjr2[which.max(reg.summary$adjr2)], \n",
                "       col=\"red\",cex=2,pch=20)\n",
                "plot(regfit.full,scale=\"adjr2\")\n",
                "\n",
                "# C_p\n",
                "plot(reg.summary$cp ,xlab=\"Number of Predictors\",ylab=\"Cp\", type=\"l\")\n",
                "points(which.min(reg.summary$cp),reg.summary$cp[which.min(reg.summary$cp)],\n",
                "       col=\"red\",cex=2,pch=20)\n",
                "plot(regfit.full,scale=\"Cp\")\n",
                "\n",
                "# BIC\n",
                "plot(reg.summary$bic ,xlab=\"Number of Predictors\",ylab=\"BIC\", type=\"l\")\n",
                "points(which.min(reg.summary$bic),reg.summary$bic[which.min(reg.summary$bic)],\n",
                "       col=\"red\",cex=2,pch=20)\n",
                "plot(regfit.full,scale=\"bic\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Knowledge Check 6**\n",
                "\n",
                "Find the optimal number of predictors based on the adjusted training errors Adjusted $R^2$, $C_p$, and $BIC$.\n",
                "\n",
                "**Answer:**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "library(leaps)\n",
                "predictors = ncol(contacts)-1\n",
                "regfit.full = regsubsets(Visits ~ ., data = contacts, nvmax=predictors)\n",
                "reg.summary = summary(regfit.full)\n",
                "\n",
                "# Adjusted R-Squared\n",
                "plot(reg.summary$adjr2 ,xlab=\"Number of Predictors\",ylab=\"Adjusted R-Squared\",type=\"l\")\n",
                "points(which.max(reg.summary$adjr2),reg.summary$adjr2[which.max(reg.summary$adjr2)], \n",
                "       col=\"red\",cex=2,pch=20)\n",
                "\n",
                "# C_p\n",
                "plot(reg.summary$cp ,xlab=\"Number of Predictors\",ylab=\"Cp\", type=\"l\")\n",
                "points(which.min(reg.summary$cp),reg.summary$cp[which.min(reg.summary$cp)],\n",
                "       col=\"red\",cex=2,pch=20)\n",
                "\n",
                "# BIC\n",
                "plot(reg.summary$bic ,xlab=\"Number of Predictors\",ylab=\"BIC\", type=\"l\")\n",
                "points(which.min(reg.summary$bic),reg.summary$bic[which.min(reg.summary$bic)],\n",
                "       col=\"red\",cex=2,pch=20)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**For the following three performance metrics, the optimal number of predictors is**\n",
                "\n",
                "**Adjusted $R^2$** \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "which.max(reg.summary$adjr2)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "**$C_p$:**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "which.min(reg.summary$cp)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "**$BIC$:**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "which.min(reg.summary$bic)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**IV.B. Directly Estimate the Test Error (Cross-Validation)**\n",
                "\n",
                "Define the `predict` function\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "predict.regsubsets = function (object, newdata, id,...){\n",
                "  form=as.formula(object$call[[2]])\n",
                "  mat=model.matrix(form,newdata)\n",
                "  coefi=coef(object, id=id)\n",
                "  xvars=names(coefi)\n",
                "  mat[,xvars]%*%coefi\n",
                "}\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "Define the model tuning parameter values\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "k=10\n",
                "set.seed (1)\n",
                "folds=sample(1:k,nrow(visits),replace=TRUE)\n",
                "predictors = ncol(visits)-1\n",
                "cv.errors=matrix(NA, k, predictors, dimnames=list(NULL, paste(1:predictors)))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "1. Compute $k$ (cross-validated) test errors for all $j$-variable models\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for(j in 1:k){\n",
                "  best.fit = regsubsets(Visits ~ ., data = visits[folds!=j,], nvmax = predictors)\n",
                "  for(i in 1:predictors){\n",
                "    pred = predict(best.fit, visits[folds==j,], id=i)\n",
                "    cv.errors[j,i] = mean((visits$Visits[folds==j]-pred)^2)\n",
                "  }\n",
                "}\n",
                "cv.errors\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "2. Average over the $k$ CV test errors and plot the means\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "(mean.cv.errors=apply(cv.errors ,2 ,mean))\n",
                "arg_min_cv = which.min(mean.cv.errors)\n",
                "min_cv     = round(mean.cv.errors[arg_min_cv],2)\n",
                "  \n",
                "par(mfrow=c(1,1))\n",
                "labels = matrix(c(\"Minimum 10-Fold CV Test MSE:\", min_cv), nrow=1, ncol=2) \n",
                "mylabels = paste(labels[,1], labels[,2])\n",
                "plot(mean.cv.errors, type=\"l\", xlab=\"Number of Predictors\", ylab=\"Average CV Test Error\",\n",
                "     col=\"darkblue\", lwd=1, pch=15, cex = 0.8, bty=\"l\")\n",
                "points(arg_min_cv,min_cv,col=\"darkblue\",cex=1,pch=16)\n",
                "legend(\"top\", legend = mylabels, col = c(\"darkblue\"), pch = c(16), bty = \"n\", \n",
                "       text.col = c(\"darkblue\"), horiz = F)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "3. Reestimate all models with\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "arg_min_cv\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "variables on the *full* data set and retain the one with the smallest RSS\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "reg.best = regsubsets(Visits ~ ., data = visits, nvmax = predictors)\n",
                "(summary(reg.best))                   # Show which predictors to retain\n",
                "round(coef(reg.best,arg_min_cv),2)    # Show coefficient estimates\n",
                "round(lm(Visits ~ ., visits)$coef,2)  # Compare to full model (\"the least squares fit\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### V. Shrinkage Methods\n",
                "\n",
                "**V.A. Setup**\n",
                "\n",
                "Declare matrix of predictors x and response variable y\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "x = model.matrix(Visits ~ ., data = visits)[,-1] \n",
                "y = visits$Visits\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "Split data set into training and test sets\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "set.seed (1)\n",
                "train = sample(1:nrow(x), round(nrow(x)/2))\n",
                "test = (-train)\n",
                "y.test = y[test]\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "Load `glmnet` package\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "library(glmnet)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**V.B. Ridge Regression**\n",
                "\n",
                "Compute value of $\\lambda$ (lambda) that minimizes the CV MSE for the *training* set\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "set.seed (1)\n",
                "cv.out = cv.glmnet(x[train,], y[train], alpha=0)\n",
                "plot(cv.out)\n",
                "(bestlam = cv.out$lambda.min)\n",
                "log(bestlam)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "Compute the test MSE\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ridge.mod=glmnet(x[train,],y[train],alpha=0,lambda=bestlam)\n",
                "ridge.pred=predict(ridge.mod,s=bestlam ,newx=x[test,])\n",
                "mean((ridge.pred-y.test)^2)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "Print coefficient estimates based on optimal lambda $\\lambda^{\\ast}$ and full data set\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "out = glmnet(x,y,alpha=0,lambda=bestlam)\n",
                "round(predict(out, type=\"coefficients\", s = bestlam)[1:nrow(coef(out)),],2)\n",
                "round(lm(Visits ~ ., visits)$coef,2)  # Compare to full model (\"the least squares fit\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**V.C. The Lasso**\n",
                "\n",
                "Compute value of $\\lambda$ (lambda) that minimizes the CV MSE for the *training* set\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "set.seed (1)\n",
                "cv.out = cv.glmnet(x[train,], y[train], alpha=1)\n",
                "plot(cv.out)\n",
                "(bestlam = cv.out$lambda.min)\n",
                "log(bestlam)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "Compute the test MSE\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ridge.mod=glmnet(x[train,],y[train],alpha=1,lambda=bestlam)\n",
                "ridge.pred=predict(ridge.mod,s=bestlam ,newx=x[test,])\n",
                "mean((ridge.pred-y.test)^2)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "Print coefficient estimates based on optimal lambda $\\lambda^{\\ast}$ and full data set\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "out = glmnet(x,y,alpha=1,lambda=bestlam)\n",
                "round(predict(out, type=\"coefficients\", s = bestlam)[1:nrow(coef(out)),],2)\n",
                "round(lm(Visits ~ ., visits)$coef,2)  # Compare to full model (\"the least squares fit\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Knowledge Check 7**\n",
                "\n",
                "Find the value of $\\lambda$ and the coefficient estimates of the best model based on ridge regression.\n",
                "\n",
                "**Answer:**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "x = model.matrix(Visits ~ ., data = contacts)[,-1] \n",
                "y = contacts$Visits\n",
                "\n",
                "set.seed (1)\n",
                "train = sample(1:nrow(x), round(nrow(x)/2))\n",
                "test = (-train)\n",
                "y.test = y[test]\n",
                "\n",
                "library(glmnet)\n",
                "\n",
                "set.seed (1)\n",
                "cv.out = cv.glmnet(x[train,], y[train], alpha=0)\n",
                "plot(cv.out)\n",
                "(bestlam = cv.out$lambda.min)\n",
                "log(bestlam)\n",
                "\n",
                "out = glmnet(x,y,alpha=0)\n",
                "round(predict(out, type=\"coefficients\", s = bestlam)[1:nrow(coef(out)),],2)\n",
                "round(lm(Visits ~ ., contacts)$coef,2)  # Compare to full model (\"the least squares fit\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Knowledge Check 8**\n",
                "\n",
                "Find the value of $\\lambda$ and the coefficient estimates of the best model based on the lasso.\n",
                "\n",
                "**Answer:**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "x = model.matrix(Visits ~ ., data = contacts)[,-1] \n",
                "y = contacts$Visits\n",
                "\n",
                "set.seed (1)\n",
                "train = sample(1:nrow(x), round(nrow(x)/2))\n",
                "test = (-train)\n",
                "y.test = y[test]\n",
                "\n",
                "library(glmnet)\n",
                "\n",
                "set.seed (1)\n",
                "cv.out = cv.glmnet(x[train,], y[train], alpha=1)\n",
                "plot(cv.out)\n",
                "(bestlam = cv.out$lambda.min)\n",
                "log(bestlam)\n",
                "\n",
                "out = glmnet(x,y,alpha=1)\n",
                "round(predict(out, type=\"coefficients\", s = bestlam)[1:nrow(coef(out)),],2)\n",
                "round(lm(Visits ~ ., contacts)$coef,2)  # Compare to full model (\"the least squares fit\")\n"
            ]
        }
    ],
    "metadata": {
        "anaconda-cloud": "",
        "kernelspec": {
            "display_name": "R",
            "langauge": "R",
            "name": "ir"
        },
        "language_info": {
            "codemirror_mode": "r",
            "file_extension": ".r",
            "mimetype": "text/x-r-source",
            "name": "R",
            "pygments_lexer": "r",
            "version": "3.4.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}
